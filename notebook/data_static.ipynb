{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理数据，根目录: /mnt/j/workspace/2025math/data\n",
      "找到 2 个来源文件夹\n",
      "总共需要处理 19 个Excel文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  11%|█         | 2/19 [00:16<02:16,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误处理文件 /mnt/j/workspace/2025math/data/notxbf_com_excels_f4/341c-f0d4-70be/valid/~$341c-f0d4-70be_0.xlsx : File is not a zip file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度: 100%|██████████| 19/19 [01:40<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据处理完成！\n",
      "训练-非TxBF 行数: 20369\n",
      "训练- TxBF 行数: 27549\n",
      "验证-非TxBF 行数: 20369\n",
      "验证- TxBF 行数: 27549\n",
      "总数据行数: 95836\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "root = Path('/mnt/j/workspace/2025math/data')\n",
    "\n",
    "\n",
    "def _concat_safe(lst):\n",
    "    lst = [x for x in lst if isinstance(x, pd.DataFrame) and len(x)]\n",
    "    return pd.concat(lst, ignore_index=True) if lst else pd.DataFrame()\n",
    "\n",
    "\n",
    "def process_excel_files_to_csv():\n",
    "    train_rows_non, train_rows_txbf = [], []\n",
    "    valid_rows_non, valid_rows_txbf = [], []\n",
    "\n",
    "    print('开始处理数据，根目录:', root)\n",
    "    source_dirs = [d for d in root.iterdir() if d.is_dir()]\n",
    "    print('找到', len(source_dirs), '个来源文件夹')\n",
    "\n",
    "    all_files_to_process = []\n",
    "    for source_dir in source_dirs:\n",
    "        terminal_dirs = [d for d in source_dir.iterdir() if d.is_dir()]\n",
    "        for terminal_dir in terminal_dirs:\n",
    "            terminal_id = terminal_dir.name\n",
    "            train_dir = terminal_dir / 'train'\n",
    "            if train_dir.exists():\n",
    "                for f in train_dir.glob('*.xlsx'):\n",
    "                    all_files_to_process.append((f, 'train', terminal_id))\n",
    "            valid_dir = terminal_dir / 'valid'\n",
    "            if valid_dir.exists():\n",
    "                for f in valid_dir.glob('*.xlsx'):\n",
    "                    all_files_to_process.append((f, 'valid', terminal_id))\n",
    "\n",
    "    print('总共需要处理', len(all_files_to_process), '个Excel文件')\n",
    "\n",
    "    for excel_file, split_type, terminal_id in tqdm(all_files_to_process, desc='处理文件进度'):\n",
    "        try:\n",
    "            df = pd.read_excel(excel_file,engine='openpyxl')\n",
    "\n",
    "            # 添加终端名称列\n",
    "            df['terminal_id'] = terminal_id\n",
    "            df['source_file'] = str(excel_file)\n",
    "\n",
    "            # 波束赋型开启指示列\n",
    "            df['beamforming_en'] = df.get('beamforming_en', 0)\n",
    "            df['beamforming_en'] = pd.to_numeric(df['beamforming_en'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "            # 按条件拆分数据\n",
    "            df_txbf = df[df['beamforming_en'] == 1].copy()\n",
    "            df_non = df[df['beamforming_en'] == 0].copy()\n",
    "\n",
    "            # 训练 / 验证分别追加\n",
    "            if split_type == 'train':\n",
    "                if len(df_txbf): train_rows_txbf.append(df_txbf)\n",
    "                if len(df_non): train_rows_non.append(df_non)\n",
    "            else:\n",
    "                if len(df_txbf): valid_rows_txbf.append(df_txbf)\n",
    "                if len(df_non): valid_rows_non.append(df_non)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('错误处理文件', excel_file, ':', e)\n",
    "\n",
    "    # 合并结果并保存为 CSV\n",
    "    train_non = _concat_safe(train_rows_non)\n",
    "    train_txbf = _concat_safe(train_rows_txbf)\n",
    "    valid_non = _concat_safe(valid_rows_non)\n",
    "    valid_txbf = _concat_safe(valid_rows_txbf)\n",
    "\n",
    "    train_non_csv = root / 'train_all_non_txbf.csv'\n",
    "    train_txbf_csv = root / 'train_all_txbf.csv'\n",
    "    valid_non_csv = root / 'valid_all_non_txbf.csv'\n",
    "    valid_txbf_csv = root / 'valid_all_txbf.csv'\n",
    "    combined_csv = root / 'combined_all.csv'\n",
    "\n",
    "    if len(train_non): train_non.to_csv(train_non_csv, index=False)\n",
    "    if len(train_txbf): train_txbf.to_csv(train_txbf_csv, index=False)\n",
    "    if len(valid_non): valid_non.to_csv(valid_non_csv, index=False)\n",
    "    if len(valid_txbf): valid_txbf.to_csv(valid_txbf_csv, index=False)\n",
    "\n",
    "    combined_all = _concat_safe([train_non, train_txbf, valid_non, valid_txbf])\n",
    "    if len(combined_all): combined_all.to_csv(combined_csv, index=False)\n",
    "\n",
    "    print('数据处理完成！')\n",
    "    print('训练-非TxBF 行数:', len(train_non))\n",
    "    print('训练- TxBF 行数:', len(train_txbf))\n",
    "    print('验证-非TxBF 行数:', len(valid_non))\n",
    "    print('验证- TxBF 行数:', len(valid_txbf))\n",
    "    print('总数据行数:', len(combined_all))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_excel_files_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_diagnose(sinr_list, y, alpha_probe=1.0, beta_probe=1.0, domain_hint=\"db\"):\n",
    "    import numpy as np\n",
    "    from scipy.stats import spearmanr\n",
    "\n",
    "    lens = np.array([np.isfinite(s).sum() for s in sinr_list])\n",
    "    means = np.array([np.nanmean(s) for s in sinr_list])\n",
    "    stds  = np.array([np.nanstd(s)  for s in sinr_list])\n",
    "\n",
    "    print(\"[DGN] y stats: mean/std/min/max =\", np.nanmean(y), np.nanstd(y), np.nanmin(y), np.nanmax(y))\n",
    "    print(\"[DGN] SC len:  min/median/max    =\", np.nanmin(lens), np.median(lens), np.nanmax(lens))\n",
    "    print(\"[DGN] SC mean:  mean±std ≈       =\", np.nanmean(means), np.nanstd(means))\n",
    "    print(\"[DGN] SC std:   mean±std ≈       =\", np.nanmean(stds), np.nanstd(stds))\n",
    "\n",
    "    def eesm_xeff_list(slist, alpha, beta, db=True):\n",
    "        out = []\n",
    "        for s in slist:\n",
    "            s = np.asarray(s, float)\n",
    "            s = s[np.isfinite(s)]\n",
    "            if s.size == 0: out.append(np.nan); continue\n",
    "            if db:\n",
    "                x = -s / max(beta,1e-12)\n",
    "                m = np.max(x); lme = m + np.log(np.mean(np.exp(x - m)))\n",
    "                out.append(-alpha*lme)\n",
    "            else:\n",
    "                s_lin = 10.0**(s/10.0)  # dB->linear\n",
    "                x = -s_lin / max(beta,1e-12)\n",
    "                m = np.max(x); lme = m + np.log(np.mean(np.exp(x - m)))\n",
    "                out.append(-alpha*lme)\n",
    "        return np.array(out, float)\n",
    "\n",
    "    xeff_db  = eesm_xeff_list(sinr_list, alpha_probe, beta_probe, db=True)\n",
    "    xeff_lin = eesm_xeff_list(sinr_list, alpha_probe, beta_probe, db=False)\n",
    "\n",
    "    sp_db  = spearmanr(xeff_db,  y, nan_policy=\"omit\").correlation\n",
    "    sp_lin = spearmanr(xeff_lin, y, nan_policy=\"omit\").correlation\n",
    "    print(f\"[DGN] Spearman(xeff_db, y)  = {sp_db:.4f}\")\n",
    "    print(f\"[DGN] Spearman(xeff_lin, y) = {sp_lin:.4f}\")\n",
    "    print(\"[DGN] xeff_db  mean/std/min/max =\", np.nanmean(xeff_db),  np.nanstd(xeff_db),  np.nanmin(xeff_db),  np.nanmax(xeff_db))\n",
    "    print(\"[DGN] xeff_lin mean/std/min/max =\", np.nanmean(xeff_lin), np.nanstd(xeff_lin), np.nanmin(xeff_lin), np.nanmax(xeff_lin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid α–β (Spearman): 100%|██████████████████| 1008/1008 [03:52<00:00,  4.34it/s]\n",
      "Grid α–β (Spearman): 100%|████████████████| 11220/11220 [40:38<00:00,  4.60it/s]\n",
      "[NM-rank   100] loss=0.240609 α=0.2405 β=3.195\n",
      "[NM-rank   200] loss=0.24061 α=0.2405 β=3.195\n",
      "[NM-rank   300] loss=0.240631 α=0.08945 β=3.094\n",
      "[NM-rank   400] loss=0.24062 α=0.08945 β=3.094\n",
      "[NM-rank   500] loss=0.240608 α=0.08945 β=3.094\n",
      "[NM-rank   600] loss=0.240608 α=0.08945 β=3.094\n",
      "[NM-rank   700] loss=0.240608 α=0.08945 β=3.094\n",
      "[NM-rank   800] loss=0.240608 α=0.08945 β=3.094\n",
      "[NM-rank   900] loss=0.240608 α=0.08945 β=3.094\n"
     ]
    }
   ],
   "source": [
    "!python .\\models\\eesm.py \\\n",
    "  --train '/mnt/j/workspace/2025math/datasets/train_all_non_txbf.csv' \\\n",
    "  --valid '/mnt/j/workspace/2025math/datasets/valid_all_non_txbf.csv' \\\n",
    "  --per_sc_col sinr_per_sc_non \\\n",
    "  --label_col mcs \\\n",
    "  --outdir .results/eesm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DGN] y stats: mean/std/min/max = 320.9596985615396 98.15744074583127 103.2 619.4\n",
      "[DGN] SC len:  min/median/max    = 122 122.0 122\n",
      "[DGN] SC mean:  mean±std ≈       = 93069.81729650633 725513.7899031631\n",
      "[DGN] SC std:   mean±std ≈       = 2.964404670616789e-11 2.7615410022012386e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/chatpatent/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in power\n",
      "/root/miniconda3/envs/chatpatent/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DGN] Spearman(xeff_db, y)  = 0.7593\n",
      "[DGN] Spearman(xeff_lin, y) = 0.6146\n",
      "[DGN] xeff_db  mean/std/min/max = 93069.81729650633 725513.7899031631 0.238264857411604 13398617.5663131\n",
      "[DGN] xeff_lin mean/std/min/max = 7.205044604308805e+298 inf 1.056395361828082 9.071596671309913e+299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/chatpatent/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1550: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def parse_float_array_from_string(s: str):\n",
    "    import numpy as np, re\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return np.full(0, np.nan)\n",
    "    if isinstance(s, (list, np.ndarray)):\n",
    "        return np.array(s, dtype=float)\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return np.full(0, np.nan)\n",
    "    try:\n",
    "        parts = s.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "        return np.array([float(p) for p in parts if p.strip() != \"\"], dtype=float)\n",
    "    except Exception:\n",
    "        ss = s.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        parts = re.split(r\"[, \\t]+\", ss)\n",
    "        vals = []\n",
    "        for p in parts:\n",
    "            try:\n",
    "                vals.append(float(p))\n",
    "            except Exception:\n",
    "                continue\n",
    "        return np.array(vals, dtype=float)\n",
    "\n",
    "# -----------------------------\n",
    "train_path = Path(\"/mnt/j/workspace/2025math/datasets/train_all_non_txbf.csv\")\n",
    "per_sc_col = \"sinr_per_sc_non\"   \n",
    "label_col  = \"mcs\"               \n",
    "# -----------------------------\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "sinr_list = [parse_float_array_from_string(s) for s in df[per_sc_col]]\n",
    "y = pd.to_numeric(df[label_col], errors=\"coerce\").values\n",
    "\n",
    "quick_diagnose(sinr_list, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatpatent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
